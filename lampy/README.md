# Lampy

Numpy for Open-Lambda.

[TOC]

## Possible Approach

- **Sparx approach**: We always have the whole information about what to compute. We construct, optimize and dispatch computational diagram.
- **Just-in-time approach**: We expect changes and flexibility. We do just-in-time call of parallelization. We respect regions of parallelism.







## References

- [Tensorflow: A System for Large-Scale Machine Learning](https://www.tensorflow.org/about/bib)
- [Tensorflow: Large-Scale Machine Learning on Heterogeneous Distributed Systems](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45166.pdf)
- [Thrust](https://github.com/thrust/thrust/wiki)
- [Numpy](https://arxiv.org/pdf/1102.1523.pdf)
- [Julia](https://github.com/JuliaLang/julia/tree/v1.1.0)

